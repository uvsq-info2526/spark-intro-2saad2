{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/29 14:31:34 WARN Utils: Your hostname, sal9000 resolves to a loopback address: 127.0.1.1; using 192.168.1.201 instead (on interface eno2)\n",
      "23/10/29 14:31:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/29 14:31:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Exemples avec les formats de stockage\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des prénoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+-----+---+--------+\n",
      "|sexe|        prenom|annee|dep|effectif|\n",
      "+----+--------------+-----+---+--------+\n",
      "|   1|_PRENOMS_RARES| 1909| 44|       7|\n",
      "|   1|_PRENOMS_RARES| 1925| 64|      19|\n",
      "|   1|_PRENOMS_RARES| 1926| 44|      21|\n",
      "|   1|_PRENOMS_RARES| 1962| 66|      15|\n",
      "|   1|_PRENOMS_RARES| 1997| 40|      15|\n",
      "|   1|_PRENOMS_RARES| 2000| 46|      13|\n",
      "|   1|_PRENOMS_RARES| 2016|973|    1463|\n",
      "|   1|      ABDALLAH| 2007| 76|       3|\n",
      "|   1|     ABDELAZIZ| 1978| 75|       3|\n",
      "|   1|    ABDELHAFID| 1964| 42|       4|\n",
      "|   1|    ABDELKADER| 2002| 78|       4|\n",
      "|   1|    ABDELMALEK| 1982| 69|       4|\n",
      "|   1|    ABDELMALIK| 1962| 75|       3|\n",
      "|   1|         ABDON| 1920|971|       5|\n",
      "|   1|     ABDOULLAH| 2016| 67|       3|\n",
      "|   1|          ABEL| 1911| 71|       6|\n",
      "|   1|          ABEL| 1921| 04|       7|\n",
      "|   1|          ABEL| 2019| 37|      15|\n",
      "|   1|     ABOUBACAR| 1994| 13|       3|\n",
      "|   1|       ABRAHAM| 2017| 75|       7|\n",
      "+----+--------------+-----+---+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "# Charge un fichier texte et convertit les lignes en \"Row\".\n",
    "lines = sc.textFile(\"prenoms_sample.txt\")\n",
    "prenoms_as_rdd = lines.map(lambda l: l.split(\";\"))\\\n",
    "    .map(lambda p: Row(\\\n",
    "        sexe=int(p[0]),\\\n",
    "        prenom=p[1],\\\n",
    "        annee=int(p[2]),\\\n",
    "        dep=p[3],\\\n",
    "        effectif=int(p[4])))\n",
    "\n",
    "# Infère le schéma et enregistre le DataFrame comme une table.\n",
    "prenoms = spark.createDataFrame(prenoms_as_rdd)\n",
    "prenoms.createOrReplaceTempView(\"prenoms\")\n",
    "prenoms.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des départements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------+----+--------------------+--------------------+--------------------+\n",
      "|dep|reg|cheflieu|tncc|                 ncc|              nccenr|             libelle|\n",
      "+---+---+--------+----+--------------------+--------------------+--------------------+\n",
      "|  1| 84|   01053|   5|                 AIN|                 Ain|                 Ain|\n",
      "|  2| 32|   02408|   5|               AISNE|               Aisne|               Aisne|\n",
      "|  3| 84|   03190|   5|              ALLIER|              Allier|              Allier|\n",
      "|  4| 93|   04070|   4|ALPES DE HAUTE PR...|Alpes-de-Haute-Pr...|Alpes-de-Haute-Pr...|\n",
      "|  5| 93|   05061|   4|        HAUTES ALPES|        Hautes-Alpes|        Hautes-Alpes|\n",
      "|  6| 93|   06088|   4|     ALPES MARITIMES|     Alpes-Maritimes|     Alpes-Maritimes|\n",
      "|  7| 84|   07186|   5|             ARDECHE|             Ardèche|             Ardèche|\n",
      "|  8| 44|   08105|   4|            ARDENNES|            Ardennes|            Ardennes|\n",
      "|  9| 76|   09122|   5|              ARIEGE|              Ariège|              Ariège|\n",
      "| 10| 44|   10387|   5|                AUBE|                Aube|                Aube|\n",
      "| 11| 76|   11069|   5|                AUDE|                Aude|                Aude|\n",
      "| 12| 76|   12202|   5|             AVEYRON|             Aveyron|             Aveyron|\n",
      "| 13| 93|   13055|   4|    BOUCHES DU RHONE|    Bouches-du-Rhône|    Bouches-du-Rhône|\n",
      "| 14| 28|   14118|   2|            CALVADOS|            Calvados|            Calvados|\n",
      "| 15| 84|   15014|   2|              CANTAL|              Cantal|              Cantal|\n",
      "| 16| 75|   16015|   3|            CHARENTE|            Charente|            Charente|\n",
      "| 17| 75|   17300|   3|   CHARENTE MARITIME|   Charente-Maritime|   Charente-Maritime|\n",
      "| 18| 24|   18033|   2|                CHER|                Cher|                Cher|\n",
      "| 19| 75|   19272|   3|             CORREZE|             Corrèze|             Corrèze|\n",
      "| 21| 27|   21231|   3|           COTE D OR|           Côte-d'Or|           Côte-d'Or|\n",
      "+---+---+--------+----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = sc.textFile(\"dpts.txt\")\n",
    "depts_as_rdd = lines\\\n",
    "    .filter(lambda l: \"dep\" not in l and \"2A\" not in l and \"2B\" not in l)\\\n",
    "    .map(lambda l: l.split(\",\"))\\\n",
    "    .map(lambda p: Row(\\\n",
    "        dep=int(p[0]),\\\n",
    "        reg=int(p[1]),\\\n",
    "        cheflieu=p[2],\\\n",
    "        tncc=p[3],\\\n",
    "        ncc=p[4],\\\n",
    "        nccenr=p[6],\\\n",
    "        libelle=p[6]))\n",
    "\n",
    "depts = spark.createDataFrame(depts_as_rdd)\n",
    "depts.createOrReplaceTempView(\"depts\")\n",
    "depts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauvegarder les données au format parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les prénoms partitionnés par départements et années et compressés (Snappy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prenoms.write\\\n",
    "    .partitionBy('dep', 'annee')\\\n",
    "        .format('parquet')\\\n",
    "            .save('prenomsParDeptsEtAnnees.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les prénoms partitionnés par départements et années et compressés (gzip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prenoms.write\\\n",
    "    .partitionBy('dep', 'annee')\\\n",
    "        .option(\"compression\", \"gzip\")\\\n",
    "            .format('parquet')\\\n",
    "                .save(\"prenomsParDeptsEtAnnees.gzip.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les départements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "depts.write\\\n",
    "    .format(\"parquet\")\\\n",
    "        .save(\"depts.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
